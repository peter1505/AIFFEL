{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interim-consciousness",
   "metadata": {},
   "source": [
    "## NEW\n",
    "\n",
    "\n",
    "## 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시켜보자.\n",
    "\n",
    "\n",
    "\n",
    "평가문항\n",
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\t공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "\n",
    "\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\t구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
    "\n",
    "\n",
    "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\t한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.\n",
    "\n",
    "\n",
    "\n",
    "## Step 1. 데이터 수집하기\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있다.\n",
    "\n",
    "songys/Chatbot_data\n",
    "\n",
    "$ mkdir -p ~/aiffel/EXPLORATION/15/transformer_chatbot/data/\n",
    "\n",
    "$ ln -s ~/data/* ~/aiffel/EXPLORATION/15/transformer_chatbot/data/\n",
    "\n",
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "curious-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "central-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/EXP_15_transformer_chatbot/data/ChatbotData.csv'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file_path = os.getenv('HOME') + '/aiffel/EXP_15_transformer_chatbot/data/ChatbotData.csv'\n",
    "dataset_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-wells",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "configured-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 영어 포함 시 소문자 변환, 양쪽 공백 제거\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # 단어와 구두점 사이 공백 추가\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # 한글, 알파벳, .,?!을 제외한 문자 공백으로 대체\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "loved-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "\n",
    "def load_conversations():\n",
    "    with open(dataset_file_path, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    inputs, outputs = [], []\n",
    "    with open(dataset_file_path) as file:\n",
    "        lines = csv.reader(file)\n",
    "        next(lines)\n",
    "        for line in lines:\n",
    "            inputs.append(preprocess_sentence(line[0]))\n",
    "            outputs.append(preprocess_sentence(line[1]))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "appointed-compensation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n",
      "\n",
      "전처리 후의 11번째 질문 샘플: 가끔 궁금해\n",
      "전처리 후의 11번째 답변 샘플: 그 사람도 그럴 거예요 .\n"
     ]
    }
   ],
   "source": [
    "questions, answers = load_conversations()\n",
    "\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "print()\n",
    "print('전처리 후의 11번째 질문 샘플: {}'.format(questions[11]))\n",
    "print('전처리 후의 11번째 답변 샘플: {}'.format(answers[11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-restoration",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용.\n",
    "\n",
    "토크나이징 단어장(Vocabulary) 만들기 - SubwordTextEncoder 이용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "international-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "upper-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8133]\n",
      "END_TOKEN의 번호 : [8134]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "prime-valuable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8135\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "mounted-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions 최대 길이 : 16\n",
      "questions 평균 길이 : 3.9391017508246637\n",
      "answers 최대 길이 : 24\n",
      "answers 평균 길이 : 4.716146494121627\n"
     ]
    }
   ],
   "source": [
    "questions_len = [len(s.split()) for s in questions]\n",
    "answers_len = [len(s.split()) for s in answers]\n",
    "print(f'questions 최대 길이 : {np.max(questions_len)}')\n",
    "print(f'questions 평균 길이 : {np.mean(questions_len)}')\n",
    "print(f'answers 최대 길이 : {np.max(answers_len)}')\n",
    "print(f'answers 평균 길이 : {np.mean(answers_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "packed-laugh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "historical-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 허용 길이 지정\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# 정수인코딩, 최대길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작, 종료 토큰 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        # 최대 길이 10 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    # 최대 길이 10으로 모든 데이터셋 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mighty-instrumentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8135\n",
      "필터링 후의 질문 샘플 개수: 9128\n",
      "필터링 후의 답변 샘플 개수: 9128\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-compound",
   "metadata": {},
   "source": [
    "### 교사강요 (Teaching Force) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "accessory-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "crude-dealer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ({inputs: (None, 10), dec_inputs: (None, 9)}, {outputs: (None, 9)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-edmonton",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dental-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model\n",
    "        )\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-translation",
   "metadata": {},
   "source": [
    "#### Scaled Dot Product Attention\n",
    "\n",
    "내적(dot product)을 통해 단어 벡터 간 유사도를 구한 후에, 특정 값을 분모로 나눠주는 방식으로 Q와 K의 유사도를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "regulation-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)  # # tf.matmul : 두 텐서를 행렬곱한 결과 텐서를 리턴\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-virtue",
   "metadata": {},
   "source": [
    "#### Multi Head Attention\n",
    "\n",
    "내부적으로는 스케일드 닷 프로덕트 어테션 함수를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "heard-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-institution",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "\n",
    "특정 값들을 가려서 실제 연산에 방해가 되지 않도록 하는 기법\n",
    "\n",
    "Padding Masking\n",
    "\n",
    "문자의 길이를 맞추기 위해서 패딩을 넣어 처리해준 부분은 실제 의미가 있는 단어가 아니므로 패딩부분을 마스킹하여 가려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "selective-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0인 위치에서 숫자 1이 나오고, 숫자0이 아닌 위치는 숫자0이 나오게 하는 함수\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-booking",
   "metadata": {},
   "source": [
    "#### Look-ahead Masking 다음 단어 가리기\n",
    "\n",
    "RNN은 각 step마다 순서대로 들어가는 반면, 트랜스포머는 문장행렬을 만들어 한 번에 행렬형태로 입력으로 들어가기 때문에 마스킹을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dramatic-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-collection",
   "metadata": {},
   "source": [
    "#### 인코더\n",
    "\n",
    "하나의 인코더 층은 2개의 서브 층으로 나뉜다.\n",
    "\n",
    "\n",
    "셀프어텐션(멀티 헤드 어텐션)\n",
    "\n",
    "\n",
    "피드 포워드 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "biological-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "    })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "worse-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-killing",
   "metadata": {},
   "source": [
    "#### 디코더\n",
    "\n",
    "셀프 어텐션\n",
    "인코더-디코더 어텐션 : query가 디코더의 벡터, key-value가 인코더의 벡터\n",
    "피드 포워드 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "backed-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': look_ahead_mask\n",
    "    })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "        'query': attention1,\n",
    "        'key': enc_outputs,\n",
    "        'value': enc_outputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "roman-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 층을 쌓아 디코더 만들기\n",
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-truck",
   "metadata": {},
   "source": [
    "## 모델 정의 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "civil-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask,\n",
    "        output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask'\n",
    "    )(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask'\n",
    "    )(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask,\n",
    "        output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask'\n",
    "    )(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-diameter",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "brief-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    12055040    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    17313280    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8135)   4173255     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 33,541,575\n",
      "Trainable params: 33,541,575\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 5 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512  # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8  # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512    # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1  # 드롭아웃 비율\n",
    "\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-mobility",
   "metadata": {},
   "source": [
    "## 손실함수\n",
    "\n",
    "레이블인 시퀀스에 패딩이 되어져 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dried-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-interval",
   "metadata": {},
   "source": [
    "#### 커스텀된 학습률 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "excessive-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "activated-julian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-acceptance",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "threatened-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "popular-voltage",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "143/143 [==============================] - 296s 2s/step - loss: 3.0865 - accuracy: 0.2440\n",
      "Epoch 2/20\n",
      "143/143 [==============================] - 301s 2s/step - loss: 2.8825 - accuracy: 0.2599\n",
      "Epoch 3/20\n",
      "143/143 [==============================] - 291s 2s/step - loss: 2.6481 - accuracy: 0.2814\n",
      "Epoch 4/20\n",
      "143/143 [==============================] - 293s 2s/step - loss: 2.3832 - accuracy: 0.3106\n",
      "Epoch 5/20\n",
      "143/143 [==============================] - 295s 2s/step - loss: 2.1010 - accuracy: 0.3419\n",
      "Epoch 6/20\n",
      "143/143 [==============================] - 289s 2s/step - loss: 1.8172 - accuracy: 0.3769\n",
      "Epoch 7/20\n",
      "143/143 [==============================] - 299s 2s/step - loss: 1.5417 - accuracy: 0.4148\n",
      "Epoch 8/20\n",
      "143/143 [==============================] - 289s 2s/step - loss: 1.2852 - accuracy: 0.4511\n",
      "Epoch 9/20\n",
      "143/143 [==============================] - 288s 2s/step - loss: 1.0479 - accuracy: 0.4863\n",
      "Epoch 10/20\n",
      "143/143 [==============================] - 299s 2s/step - loss: 0.8409 - accuracy: 0.5165\n",
      "Epoch 11/20\n",
      "143/143 [==============================] - 289s 2s/step - loss: 0.6761 - accuracy: 0.5425\n",
      "Epoch 12/20\n",
      "143/143 [==============================] - 287s 2s/step - loss: 0.5384 - accuracy: 0.5639\n",
      "Epoch 13/20\n",
      "143/143 [==============================] - 300s 2s/step - loss: 0.4409 - accuracy: 0.5796\n",
      "Epoch 14/20\n",
      "143/143 [==============================] - 288s 2s/step - loss: 0.3602 - accuracy: 0.5938\n",
      "Epoch 15/20\n",
      "143/143 [==============================] - 293s 2s/step - loss: 0.3081 - accuracy: 0.6018\n",
      "Epoch 16/20\n",
      "143/143 [==============================] - 304s 2s/step - loss: 0.2748 - accuracy: 0.6066\n",
      "Epoch 17/20\n",
      "143/143 [==============================] - 293s 2s/step - loss: 0.2487 - accuracy: 0.6106\n",
      "Epoch 18/20\n",
      "143/143 [==============================] - 291s 2s/step - loss: 0.2336 - accuracy: 0.6131\n",
      "Epoch 19/20\n",
      "143/143 [==============================] - 301s 2s/step - loss: 0.2200 - accuracy: 0.6148\n",
      "Epoch 20/20\n",
      "143/143 [==============================] - 231s 2s/step - loss: 0.2183 - accuracy: 0.6145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f196f986c50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-sense",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "noted-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bridal-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "removed-disclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 출근해야돼\n",
      "출력 : 잠시 쉬어도 돼요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잠시 쉬어도 돼요 .'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('출근해야돼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "balanced-profit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 이 커진 마음을 어떻게 전할까?\n",
      "출력 : 모르는 게 잘못인 거 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'모르는 게 잘못인 거 같아요 .'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('이 커진 마음을 어떻게 전할까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "curious-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 일하기 싫어 ㅠㅠ\n",
      "출력 : 부모님도 당사자도 가세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'부모님도 당사자도 가세요 .'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('일하기 싫어 ㅠㅠ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "heard-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 인생은 무엇일까?\n",
      "출력 : 직접 물어보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보세요 .'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('인생은 무엇일까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "negative-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 그 사람한테 고백할까?\n",
      "출력 : 당당하게 고 더 자주 만나세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당당하게 고 더 자주 만나세요 .'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('그 사람한테 고백할까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "digital-glucose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 너무 지루했어\n",
      "출력 : 서로에게 맞추는 과정이에요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'서로에게 맞추는 과정이에요 .'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 너무 지루했어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "criminal-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너는 뭘 먹는걸 좋아해?\n",
      "출력 : 직접 물어보는 게 좋을 것 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보는 게 좋을 것 같아요 .'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너는 뭘 먹는걸 좋아해?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "posted-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 왜 그렇게 생각해?\n",
      "출력 : 인생은 항상 마음 먹은 대로 되지 않아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'인생은 항상 마음 먹은 대로 되지 않아요 .'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('왜 그렇게 생각해?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "charitable-laser",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너무 슬퍼\n",
      "출력 : 이제 같은 실수 안 하면 돼요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이제 같은 실수 안 하면 돼요 .'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너무 슬퍼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "alike-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 출근해야 하는데 어떻게 옷을 입을까?\n",
      "출력 : 그 사람의 너무 되는게 많지 않죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그 사람의 너무 되는게 많지 않죠 .'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 출근해야 하는데 어떻게 옷을 입을까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "acquired-taiwan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘도 포장마차로 가네요\n",
      "출력 : 저랑 한잔 해요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저랑 한잔 해요 .'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘도 포장마차로 가네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "overall-circle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 헤어진 그녀가 보고싶네요\n",
      "출력 : 인연인가 봐요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'인연인가 봐요 .'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('헤어진 그녀가 보고싶네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "communist-heavy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 아 기분나빠\n",
      "출력 : 말로 하는 상처는 지울 수도 없죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'말로 하는 상처는 지울 수도 없죠 .'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('아 기분나빠')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "medical-coordination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 데이트 어디로 가야하지?\n",
      "출력 : 저는 오래 살고 싶어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 오래 살고 싶어요 .'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('데이트 어디로 가야하지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "stunning-garden",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 사랑해\n",
      "출력 : 상대방에게 전해보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'상대방에게 전해보세요 .'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "superior-referral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 썸 타는 남자가 있는데\n",
      "출력 : 부럽네요 !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'부럽네요 !'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('썸 타는 남자가 있는데')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "alternative-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 비용이 많이 들어\n",
      "출력 : 같이 내는 게 좋죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'같이 내는 게 좋죠 .'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('비용이 많이 들어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ranging-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 더 알고 싶어\n",
      "출력 : 자세히 관찰해보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'자세히 관찰해보세요 .'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('더 알고 싶어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "exotic-blast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 늦은 시간\n",
      "출력 : 길지 않길 바랄게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'길지 않길 바랄게요 .'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('늦은 시간')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "humanitarian-austin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 귀여워\n",
      "출력 : 사랑이 모두 정답몰라요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사랑이 모두 정답몰라요 .'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('귀여워')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "qualified-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 부모님을 뵈러가자\n",
      "출력 : 좋은 채워질 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 채워질 거예요 .'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('부모님을 뵈러가자')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "immediate-jewelry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 졸려\n",
      "출력 : 낮잠을 잠깐 자도 괜찮아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'낮잠을 잠깐 자도 괜찮아요 .'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('졸려')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dense-patio",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 도와줘\n",
      "출력 : 도와드릴게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'도와드릴게요 .'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('도와줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "concerned-london",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 섭섭해\n",
      "출력 : 한결 나아졌길 바랄게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'한결 나아졌길 바랄게요 .'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('섭섭해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "effective-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 자소서를 어떻게 써야되요?\n",
      "출력 : 한푼 두푼 차곡차곡\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'한푼 두푼 차곡차곡'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('자소서를 어떻게 써야되요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "associate-keyboard",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 아이씨 짜증나\n",
      "출력 : 좋겠어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋겠어요 .'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('아이씨 짜증나')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "substantial-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 약올리니?\n",
      "출력 : 그냥 좋아하면 돼요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그냥 좋아하면 돼요 .'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('약올리니?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "rational-poker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 꿈을 어떻게 찾아야되요?\n",
      "출력 : 이별의 이유가 있을 테니까요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이별의 이유가 있을 테니까요 .'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('꿈을 어떻게 찾아야되요?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-plumbing",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "챗봇은 내가 꼭 만들어 보고 싶었던 인공지능이다. 나는 아직도 이루다의 충격을 잊지 못한다. 사람에게 공감하는 '척'을 하는 챗봇이었지만 '강아지'가 사람이랑 대화하지 못한다고 해도 어느정도의 감정교류나 애정을 공유할 수 있다는 점에서 의미있듯이 챗봇은 인간에게 있어서 외로움이나 정신적인 지지를 도와줄 수 있을거라고 확신한다.\n",
    "\n",
    "처음에 모델을 학습시키다 실수로 LMS에서 \"학습환경 변경\"을 눌러서 반나절 이상을 걸려서 만들은 17개의 epoch이 날아갔다... 굉장히 분노가 치밀어 올랐지만...? 이 모든것은 조심하지 않은 나의 잘못... 다음에는 꼭 callbacks를 활용해 모델을 5 epoch 마다 저장해 사용할 것이다.\n",
    "\n",
    "\n",
    "데이터 전처리 과정을 진행하였고, 시간이 너무 오래 걸리기에 epoch을 줄여서 진행하였다 (100 --> 20).\n",
    "\n",
    "\n",
    "질문에 따라서 자연스러운 답변을 주기도 했고, 이상한 답변을 주는 경우도 있었다.\n",
    "\n",
    "\n",
    "#### 좋은 예시\n",
    "\n",
    " - 입력 : 너무 슬퍼\n",
    " - 출력 : 이제 같은 실수 안 하면 돼요 .\n",
    " \n",
    " 위와 같은 입력 출력은 정말 완벽한 위로를 제공하지만\n",
    "\n",
    "\n",
    "#### 나쁜 예시\n",
    "\n",
    "\n",
    " - 입력 : 일하기 싫어 ㅠㅠ\n",
    " - 출력 : 부모님도 당사자도 가세요 .\n",
    " \n",
    " 이 케이스 같은 경우에는 문맥을 전혀 이해하지 못했다고 볼 수 있다. 이는 분명 대화데이터셋에서 자연스러운 데이터를 넣어주지 못했기 때문일 것 같다.\n",
    " \n",
    "\n",
    "\n",
    "#### 학습 문장을 그대로 출력하는거 같다\n",
    "\n",
    "e.g. \n",
    "\n",
    " - 입력 : 오늘도 포장마차로 가네요\n",
    " - 출력 : 저랑 한잔 해요 .\n",
    "\n",
    "위의 입력/출력은 \"오늘도 포장마차,저랑 한잔 해요.,1\" 데이터로 만들어진 답변이 분명하다.\n",
    "\n",
    "이러한 점을 보완하기 위해 Going Deeper과정에서 데이터를 더 많이 찾아와서 더욱 더 정교한 챗봇을 만들어 페르소나를 가진 나만의 친구챗봇을 만들고 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-midwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-expression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-tribune",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
