{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "sudden-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "swiss-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  images to be resized.\n",
      "1000  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "touched-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  images to be resized.\n",
      "1000  images resized.\n",
      "rock 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"rock 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "working-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  images to be resized.\n",
      "1000  images resized.\n",
      "paper 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# paper 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"paper 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cathedral-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3000 입니다.\n",
      "x_train shape: (3000, 28, 28, 3)\n",
      "y_train shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=3000):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "artistic-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data aug by Saeyoung & Taegyun\n",
    "\n",
    "\n",
    "#Saeyoung's\n",
    "# x_int64 = x_float64.astype(np.int64)\n",
    "# numpy array float to int\n",
    "\n",
    "#Taegyun\n",
    "# x_int64 = x_float64.astype(np.int64)\n",
    "# numpy array float to int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-journalism",
   "metadata": {},
   "source": [
    "한번 이미지를 불러 볼까요?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "convertible-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-richmond",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계하기\n",
    "\n",
    "\n",
    "자 이제 데이터의 준비가 끝났습니다. 이제 여러분들이 가위바위보를 인식하는 딥러닝 네트워크를 설계해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "antique-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 11, 11, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 830,979\n",
      "Trainable params: 830,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 11, 11, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 830,979\n",
      "Trainable params: 830,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=64\n",
    "n_dense=512\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "# RGB color must be 3 \n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='elu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='elu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='elu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "unusual-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "\n",
    "# (# of data, sizr x, size y, RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-fetish",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 학습시키기\n",
    "\n",
    "\n",
    "잘 설계가 되었다면, 이제 학습을 시켜봅시다. 아마도 여러분들의 데이터는 거의 비슷비슷할 것이기 때문에 accuracy가 꽤 높게 나올 것입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "vocational-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 1s 4ms/step - loss: 1.2097 - accuracy: 0.4251\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.7295\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7853\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8248\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.8441\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8793\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.9151\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9082\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.2153 - accuracy: 0.9227\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f25a4704d10>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#todo = create model\n",
    "\n",
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "\n",
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)\n",
    "\n",
    "# 모델 시험\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-crisis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "approved-thread",
   "metadata": {},
   "source": [
    "### 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "\n",
    "\n",
    "여러분들은 300장의 가위바위보 이미지를 만들어 모두 학습에 사용했습니다. 그러므로 테스트 데이터가 없죠. 옆 친구의 이미지 데이터 300장을 받아오세요. 그리고 그것을 테스트 데이터로 하여 test accuracy를 측정해보세요. (만약 웹캠이 없는 경우 섹션을 진행하신 경우, 이미 test 데이터셋이 준비돼있으니 친구에게 조르지 않으셔도 됩니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "orange-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99  images to be resized.\n",
      "99  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "99  images to be resized.\n",
      "99  images resized.\n",
      "paper 이미지 resize 완료!\n",
      "99  images to be resized.\n",
      "99  images resized.\n",
      "rock 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# paper 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"paper 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# rock 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"rock 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "hungry-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 297 입니다.\n",
      "x_test shape: (3000, 28, 28, 3)\n",
      "y_test shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_train.shape))\n",
    "print(\"y_test shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-project",
   "metadata": {},
   "source": [
    "테스트용 데이터가 준비되었으니, 위에서 훈련시킨 model을 사용하여 test_accuracy를 측정해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "empirical-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 0s - loss: 49.3100 - accuracy: 0.9277\n",
      "test_loss: 49.31000900268555 \n",
      "test_accuracy: 0.9276666641235352\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-messaging",
   "metadata": {},
   "source": [
    "### 더 좋은 네트워크 만들어보기\n",
    "\n",
    "\n",
    "시험용 데이터x_test에 대한 인식률 test accuracy가 train accuracy보다 많이 낮게 나오지는 않았나요? 만약 그렇다면 그 이유는 무엇일까요? MNIST 손글씨 데이터 때처럼 test accuracy가 train accuracy에 근접하도록 개선 방법을 찾아 봅시다.\n",
    "\n",
    "\n",
    "\n",
    "### 노드를 마치며...\n",
    "여러분 미니 프로젝트는 잘 마치셨나요? 여러분은 이번 노드를 통해 다음의 내용을 배웠습니다.\n",
    "\n",
    "이미 잘 정제된 10개 클래스의 숫자 손글씨 데이터를 분류하는 classifier 만들기\n",
    "정제되지 않은 웹캠 사진으로부터 데이터 만들어보기\n",
    "흑백 사진이 아닌 컬러 사진을 학습하는 classifier 만들기\n",
    "분류하고자 하는 클래스의 개수를 마음대로 조절하기 (10개에서 3개로)\n",
    "그러면 오늘 배운 내용을 바탕으로 마스크 쓴 사람과 안 쓴 사람을 구분하는 프로젝트도 금방 만드실 수 있겠죠? AIFFEL 입구에서 마스크 안 쓴 사람을 자동으로 감지하고 알람을 주는 시스템을 만들어 주실 용자분 계실까요?!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-sharing",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ruled-television",
   "metadata": {},
   "source": [
    "### git 복습\n",
    "\n",
    "git init or git clone <-권장 #현재 디렉토리를 버전 저장소로 만듭니다. \n",
    "\n",
    "git config --global user.name <닉넴> #이 설정은 /.gitconfig파일에 저장되고 1번만 해주면 됩니다. \n",
    "\n",
    "git config --global user.email <이메일> \n",
    "\n",
    "git remote add origin <user_id>:<user_pw_token> \n",
    "\n",
    "git clone <user_id>:<user_pw_token>@repo주소 \n",
    "\n",
    "git config -l(L소문자) # 위 설정값 확인, 실수 있으면 수정 가능\n",
    "\n",
    "git status # git 현재상태 확인 git add \"File Name\" # 현재 변동사항 전부 commit하고 싶다는 표현.\n",
    "\n",
    "git commit -m <설명> #commit 및 설명 \n",
    "\n",
    "git branch -M main \n",
    "git config --system --unset credential.helper # config 값 초기화 f\n",
    "\n",
    "\n",
    "etal authentication failed for github 오류시 git config credential.helper.store # 토큰 재입력 안해도 괜찮아집니다. \n",
    "\n",
    "git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-raising",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
